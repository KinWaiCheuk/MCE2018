{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "import matplotlib \n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restricting GPU memory\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "gpu = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpu[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataloader, TNN, evaluation # Loading helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev2train = dataloader.creating_id_mapping()\n",
    "\n",
    "# Getting i-vectors\n",
    "trn_bl_ivector, trn_bg_ivector, dev_bl_ivector, dev_bg_ivector, tst_ivector = dataloader.get_ivectors()\n",
    "\n",
    "# Loading labels for task 2\n",
    "trn_bl_id, trn_bg_id, dev_bl_id, dev_bg_id, tst_id = dataloader.get_spk_ids()\n",
    "\n",
    "# Making labels for task 1\n",
    "trn_ivector = np.append(trn_bl_ivector, trn_bg_ivector,axis=0) # combining bg and bl speakers into a single vector\n",
    "trn_trials = np.append( np.ones([len(trn_bl_ivector), 1]), np.zeros([len(trn_bg_ivector), 1]))\n",
    "dev_ivector = np.append(dev_bl_ivector, dev_bg_ivector,axis=0) # combining bg and bl\n",
    "dev_trials = np.append( np.ones([len(dev_bl_id), 1]), np.zeros([len(dev_bg_id), 1]))\n",
    "tst_trials = dataloader.get_tst_trials()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "anchor_input (InputLayer)       (None, 600)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "positive_input (InputLayer)     (None, 600)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "negative_input (InputLayer)     (None, 600)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 600)          360600      anchor_input[0][0]               \n",
      "                                                                 positive_input[0][0]             \n",
      "                                                                 negative_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1800)         0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "                                                                 sequential_1[3][0]               \n",
      "==================================================================================================\n",
      "Total params: 360,600\n",
      "Trainable params: 360,600\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model, anchor_input, encoded_anchor = TNN.create_TNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(embedding, bl_ivector_embedding, labels):\n",
    "    spk_mean, _ = dataloader.make_spkvec(bl_ivector_embedding,labels)\n",
    "    # This accuracy calcultion is provided by MCE2018\n",
    "    scores = spk_mean.dot(embedding.transpose())\n",
    "    blscores = spk_mean.dot(bl_ivector_embedding.transpose()) # This will be used in normalization and task 2\n",
    "    \n",
    "    # Multi-target normalization\n",
    "    mnorm_mu = np.mean(blscores,axis=1) \n",
    "    mnorm_std = np.std(blscores,axis=1)\n",
    "    for iter in range(np.shape(scores)[1]):\n",
    "        scores[:,iter]= (scores[:,iter] - mnorm_mu) / mnorm_std\n",
    "    pred_scores = np.max(scores,axis=0)\n",
    "\n",
    "    return pred_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting TNN embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = Model(inputs=anchor_input, outputs=encoded_anchor)\n",
    "trained_model.load_weights('./task2_trainall/triplet_Dense600_87nd_err285_C0.5.hdf5')\n",
    "transformed_trn_bl_ivector = trained_model.predict(trn_bl_ivector)\n",
    "transformed_dev_ivector = trained_model.predict(dev_ivector)\n",
    "transformed_trn_ivector = trained_model.predict(trn_ivector)\n",
    "transformed_tst_ivector = trained_model.predict(tst_ivector)\n",
    "transformed_dev_bl_ivector = trained_model.predict(dev_bl_ivector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating on dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top S detector EER is 0.94%\n"
     ]
    }
   ],
   "source": [
    "predictions = cosine_similarity(transformed_dev_ivector, transformed_trn_bl_ivector, trn_bl_id)\n",
    "err = dataloader.calculate_EER(dev_trials,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating on testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on trainset only, test on testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top S detector EER is 8.49%\n"
     ]
    }
   ],
   "source": [
    "predictions = cosine_similarity(transformed_tst_ivector, transformed_trn_bl_ivector, trn_bl_id)\n",
    "err = dataloader.calculate_EER(tst_trials,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on trainset and devset, test on testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top S detector EER is 9.06%\n"
     ]
    }
   ],
   "source": [
    "# getting dev ids to train id conversion\n",
    "dev_bl_id_along_trnset = []\n",
    "for iter in range(len(dev_bl_id)):\n",
    "    dev_bl_id_along_trnset.extend([dev2train[dev_bl_id[iter]]])\n",
    "\n",
    "combined_embedding = np.append(transformed_trn_ivector,transformed_dev_bl_ivector,0)\n",
    "combined_labels = np.append(trn_bl_id,dev_bl_id_along_trnset)\n",
    "predictions = cosine_similarity(transformed_tst_ivector, combined_embedding, combined_labels)\n",
    "err = dataloader.calculate_EER(tst_trials,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
