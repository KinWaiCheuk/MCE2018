{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from keras.layers import Input, Conv2D, Lambda, concatenate, Dense, Flatten,MaxPooling2D,Activation\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# from keras.backend.tensorflow_backend import set_session\n",
    "# tf.config.gpu.set_per_process_memory_fraction(0.75)\n",
    "# tf.config.gpu.set_per_process_memory_growth(True)\n",
    "\n",
    "# config = tf.compat.v1.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.2\n",
    "# set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "data/bl_matching.csv not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-aa7de810d082>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m## making dictionary to find blacklist pair between train and test dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mbl_match\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/bl_matching.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'str'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdev2train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdev2id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows)\u001b[0m\n\u001b[1;32m    960\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    963\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.6/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.6/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    622\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    623\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 624\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: data/bl_matching.csv not found."
     ]
    }
   ],
   "source": [
    "# alpha = 5\n",
    "adam_optim = Adam(lr=1e-5, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "## making dictionary to find blacklist pair between train and test dataset\n",
    "bl_match = np.loadtxt('data/bl_matching.csv',dtype='str')\n",
    "dev2train={}\n",
    "dev2id={}\n",
    "train2dev={}\n",
    "train2id={}\n",
    "test2train={}\n",
    "train2test={}\n",
    "for iter, line in enumerate(bl_match):\n",
    "    line_s = line.split(',')\n",
    "    dev2train[line_s[1].split('_')[-1]]= line_s[3].split('_')[-1]\n",
    "    dev2id[line_s[1].split('_')[-1]]= line_s[0].split('_')[-1]\n",
    "    train2dev[line_s[3].split('_')[-1]]= line_s[1].split('_')[-1]\n",
    "    train2id[line_s[3].split('_')[-1]]= line_s[0].split('_')[-1]\n",
    "    test2train[line_s[2].split('_')[-1]]= line_s[3].split('_')[-1]\n",
    "    train2test[line_s[3].split('_')[-1]]= line_s[2].split('_')[-1]\n",
    "    \n",
    "def load_ivector(filename):\n",
    "    utt = np.loadtxt(filename,dtype='str',delimiter=',',skiprows=1,usecols=[0])\n",
    "    ivector = np.loadtxt(filename,dtype='float32',delimiter=',',skiprows=1,usecols=range(1,601))\n",
    "    spk_id = []\n",
    "    for iter in range(len(utt)):\n",
    "        spk_id = np.append(spk_id,utt[iter].split('_')[0])\n",
    "\n",
    "    return spk_id, utt, ivector\n",
    "\n",
    "def length_norm(mat):\n",
    "# length normalization (l2 norm)\n",
    "# input: mat = [utterances X vector dimension] ex) (float) 8631 X 600\n",
    "\n",
    "    norm_mat = []\n",
    "    for line in mat:\n",
    "        temp = line/np.math.sqrt(sum(np.power(line,2)))\n",
    "        norm_mat.append(temp)\n",
    "    norm_mat = np.array(norm_mat)\n",
    "    return norm_mat\n",
    "\n",
    "def make_spkvec(mat, spk_label):\n",
    "# calculating speaker mean vector\n",
    "# input: mat = [utterances X vector dimension] ex) (float) 8631 X 600\n",
    "#        spk_label = string vector ex) ['abce','cdgd']\n",
    "\n",
    "#     for iter in range(len(spk_label)):\n",
    "#         spk_label[iter] = spk_label[iter].split('_')[0]\n",
    "\n",
    "    spk_label, spk_index  = np.unique(spk_label,return_inverse=True)\n",
    "    spk_mean=[]\n",
    "    mat = np.array(mat)\n",
    "\n",
    "    # calculating speaker mean i-vector\n",
    "    for i, spk in enumerate(spk_label):\n",
    "        spk_mean.append(np.mean(mat[np.nonzero(spk_index==i)],axis=0))\n",
    "    spk_mean = length_norm(spk_mean)\n",
    "    return spk_mean, spk_label\n",
    "\n",
    "def calculate_EER(trials, scores):\n",
    "# calculating EER of Top-S detector\n",
    "# input: trials = boolean(or int) vector, 1: postive(blacklist) 0: negative(background)\n",
    "#        scores = float vector\n",
    "\n",
    "    # Calculating EER\n",
    "    fpr,tpr,threshold = roc_curve(trials,scores,pos_label=1)\n",
    "    fnr = 1-tpr\n",
    "    EER_threshold = threshold[np.argmin(abs(fnr-fpr))]\n",
    "    \n",
    "    # print EER_threshold\n",
    "    EER = fpr[np.argmin(np.absolute((fnr-fpr)))]\n",
    "    print(\"Top S detector EER is %0.2f%%\"% (EER*100))\n",
    "    return EER\n",
    "\n",
    "def get_trials_label_with_confusion(identified_label, groundtruth_label,dict4spk,is_trial ):\n",
    "# determine if the test utterance would make confusion error\n",
    "# input: identified_label = string vector, identified result of test utterance among multi-target from the detection system \n",
    "#        groundtruth_label = string vector, ground truth speaker labels of test utterances\n",
    "#        dict4spk = dictionary, convert label to target set, ex) train2dev convert train id to dev id\n",
    "\n",
    "    trials = np.zeros(len(identified_label))\n",
    "    for iter in range(0,len(groundtruth_label)):\n",
    "        enroll = identified_label[iter].split('_')[0]\n",
    "        test = groundtruth_label[iter].split('_')[0]\n",
    "        if is_trial[iter]:\n",
    "            if enroll == dict4spk[test]:\n",
    "                trials[iter]=1 # for Target trial (blacklist speaker)\n",
    "            else:\n",
    "                trials[iter]=-1 # for Target trial (backlist speaker), but fail on blacklist classifier\n",
    "                \n",
    "        else :\n",
    "            trials[iter]=0 # for non-target (non-blacklist speaker)\n",
    "    return trials\n",
    "\n",
    "\n",
    "def calculate_EER_with_confusion(scores,trials):\n",
    "# calculating EER of Top-1 detector\n",
    "# input: trials = boolean(or int) vector, 1: postive(blacklist) 0: negative(background) -1: confusion(blacklist)\n",
    "#        scores = float vector\n",
    "\n",
    "    # exclude confusion error (trials==-1)\n",
    "    scores_wo_confusion = scores[np.nonzero(trials!=-1)[0]]\n",
    "    trials_wo_confusion = trials[np.nonzero(trials!=-1)[0]]\n",
    "\n",
    "    # dev_trials contain labels of target. (target=1, non-target=0)\n",
    "    fpr,tpr,threshold = roc_curve(trials_wo_confusion,scores_wo_confusion,pos_label=1, drop_intermediate=False)\n",
    "    fnr = 1-tpr\n",
    "    EER_threshold = threshold[np.argmin(abs(fnr-fpr))]\n",
    "    \n",
    "    # EER withouth confusion error\n",
    "    EER = fpr[np.argmin(np.absolute((fnr-fpr)))]\n",
    "    \n",
    "    # Add confusion error to false negative rate(Miss rate)\n",
    "    total_negative = len(np.nonzero(np.array(trials_wo_confusion)==0)[0])\n",
    "    total_positive = len(np.nonzero(np.array(trials_wo_confusion)==1)[0])\n",
    "    fp= fpr*np.float(total_negative)  \n",
    "    fn= fnr*np.float(total_positive) \n",
    "    fn += len(np.nonzero(trials==-1)[0])\n",
    "    total_positive += len(np.nonzero(trials==-1)[0])\n",
    "    fpr= fp/total_negative\n",
    "    fnr= fn/total_positive\n",
    "\n",
    "    # EER with confusion Error\n",
    "    EER_threshold = threshold[np.argmin(abs(fnr-fpr))]\n",
    "    EER_fpr = fpr[np.argmin(np.absolute((fnr-fpr)))]\n",
    "    EER_fnr = fnr[np.argmin(np.absolute((fnr-fpr)))]\n",
    "    EER = 0.5 * (EER_fpr+EER_fnr)\n",
    "    \n",
    "    print(\"Top 1 detector EER is %0.2f%% (Total confusion error is %d)\"% ((EER*100), len(np.nonzero(trials==-1)[0])))\n",
    "    return EER,len(np.nonzero(trials==-1)[0])\n",
    "\n",
    "## Loading i-vector\n",
    "# trn_bl_id, trn_bl_utt, trn_bl_ivector = load_ivector('data/trn_blacklist.csv')\n",
    "# trn_bg_id, trn_bg_utt, trn_bg_ivector = load_ivector('data/trn_background.csv')\n",
    "# dev_bl_id, dev_bl_utt, dev_bl_ivector = load_ivector('data/dev_blacklist.csv')\n",
    "# dev_bg_id, dev_bg_utt, dev_bg_ivector = load_ivector('data/dev_background.csv')\n",
    "\n",
    "\n",
    "trn_bl_ivector = pickle.load(open('./data/trn_bl_ivector','rb'))\n",
    "trn_bg_ivector = pickle.load(open('./data/trn_bg_ivector','rb'))\n",
    "dev_bl_ivector = pickle.load(open('./data/dev_bl_ivector','rb'))\n",
    "dev_bg_ivector = pickle.load(open('./data/dev_bg_ivector','rb'))\n",
    "trn_bl_id = pickle.load(open('./data/trn_bl_id','rb'))\n",
    "trn_bg_id = pickle.load(open('./data/trn_bg_id','rb'))\n",
    "dev_bl_id = pickle.load(open('./data/dev_bl_id','rb'))\n",
    "dev_bg_id = pickle.load(open('./data/dev_bg_id','rb'))\n",
    "trn_bl_utt = pickle.load(open('./data/trn_bl_utt','rb'))\n",
    "trn_bg_utt = pickle.load(open('./data/trn_bg_utt','rb'))\n",
    "dev_bl_utt = pickle.load(open('./data/dev_bl_utt','rb'))\n",
    "dev_bg_utt = pickle.load(open('./data/dev_bg_utt','rb'))\n",
    "tst_id = pickle.load(open('./data/tst_id','rb'))\n",
    "test_utt = pickle.load(open('./data/test_utt','rb'))\n",
    "tst_ivector = pickle.load(open('./data/tst_ivector','rb'))\n",
    "\n",
    "# Calculating speaker mean vector\n",
    "spk_mean, spk_mean_label = make_spkvec(trn_bl_ivector,trn_bl_id)\n",
    "\n",
    "#length normalization\n",
    "\n",
    "trn_bl_ivector = length_norm(trn_bl_ivector)\n",
    "trn_bg_ivector = length_norm(trn_bg_ivector)\n",
    "dev_bl_ivector = length_norm(dev_bl_ivector)\n",
    "dev_bg_ivector = length_norm(dev_bg_ivector)\n",
    "tst_ivector = length_norm(tst_ivector)\n",
    "\n",
    "filename = 'data/tst_evaluation_keys.csv'\n",
    "tst_info = np.loadtxt(filename,dtype='str',delimiter=',',skiprows=1,usecols=range(0,3))\n",
    "tst_trials = []\n",
    "tst_trials_label = []\n",
    "tst_ground_truth =[]\n",
    "for iter in range(len(tst_info)):\n",
    "    tst_trials_label.extend([tst_info[iter,0]])\n",
    "    if tst_info[iter,1]=='background':\n",
    "        tst_trials = np.append(tst_trials,0)\n",
    "        \n",
    "    else:\n",
    "        tst_trials = np.append(tst_trials,1)\n",
    "\n",
    "\n",
    "# making trials of Dev set\n",
    "dev_ivector = np.append(dev_bl_ivector, dev_bg_ivector,axis=0)\n",
    "dev_trials = np.append( np.ones([len(dev_bl_id), 1]), np.zeros([len(dev_bg_id), 1]))\n",
    "\n",
    "trn_ivector = np.append(trn_bl_ivector, trn_bg_ivector,axis=0)\n",
    "trn_trials = np.append( np.ones([len(trn_bl_ivector), 1]), np.zeros([len(trn_bg_ivector), 1]))\n",
    "\n",
    "print('\\nDev set score using train set :')\n",
    "# Cosine distance scoring\n",
    "scores = spk_mean.dot(dev_ivector.transpose())\n",
    "\n",
    "# Multi-target normalization\n",
    "blscores = spk_mean.dot(trn_bl_ivector.transpose())\n",
    "mnorm_mu = np.mean(blscores,axis=1)\n",
    "mnorm_std = np.std(blscores,axis=1)\n",
    "for iter in range(np.shape(scores)[1]):\n",
    "    scores[:,iter]= (scores[:,iter] - mnorm_mu) / mnorm_std\n",
    "dev_scores = np.max(scores,axis=0)\n",
    "\n",
    "# Top-S detector EER\n",
    "dev_EER = calculate_EER(dev_trials, dev_scores)\n",
    "\n",
    "#divide trial label into target and non-target, plus confusion error(blacklist, fail at blacklist detector)\n",
    "dev_identified_label = spk_mean_label[np.argmax(scores,axis=0)]\n",
    "dev_trials_label = np.append( dev_bl_id,dev_bg_id)\n",
    "dev_trials_utt_label = np.append( dev_bl_utt,dev_bg_utt)\n",
    "\n",
    "# Top-1 detector EER\n",
    "dev_trials_confusion = get_trials_label_with_confusion(dev_identified_label, dev_trials_label, dev2train, dev_trials )\n",
    "dev_EER_confusion,trials = calculate_EER_with_confusion(dev_scores,dev_trials_confusion)\n",
    "\n",
    "# Generating submission file on Dev set for example\n",
    "# filename = 'teamname_fixed_primary.csv'\n",
    "# filename = 'teamname_fixed_contrastive1.csv'\n",
    "# with open(filename, \"w\") as text_file:\n",
    "#     for iter,score in enumerate(dev_scores):\n",
    "#         id_in_trainset = dev_identified_label[iter].split('_')[0]\n",
    "#         input_file = dev_trials_utt_label[iter]\n",
    "#         text_file.write('%s,%s,%s\\n' % (input_file,score,train2id[id_in_trainset]))\n",
    "\n",
    "    \n",
    "## Creating dictionary for label conversion\n",
    "\n",
    "id_set = sorted(set(trn_bl_id))\n",
    "\n",
    "id2int = {}\n",
    "for i,spk_id in enumerate(id_set):\n",
    "    id2int[spk_id] = i\n",
    "\n",
    "int2id = {v: k for k, v in id2int.items()}\n",
    "\n",
    "\n",
    "## Generating subclass for Testing\n",
    "\n",
    "classes = 3631\n",
    "\n",
    "## Generating (Anchor, Positive, Negative) pairs for One-shot-learning\n",
    "\n",
    "def triplet_generation_v2(x,y,testsize=0.3,ap_pairs=10,an_pairs=10):\n",
    "    data_xy = tuple([x,y])\n",
    "\n",
    "    trainsize = 1-testsize\n",
    "\n",
    "    triplet_train_pairs = []\n",
    "    triplet_test_pairs = []\n",
    "    for data_class in sorted(set(data_xy[1])):\n",
    "\n",
    "        same_class_idx = np.where((data_xy[1] == data_class))[0]\n",
    "        diff_class_idx = np.where(data_xy[1] != data_class)[0]       \n",
    "        if same_class_idx.shape[0] < 15:\n",
    "            same_class_sampleer_idx = random.choice(range(len(same_class_idx)))\n",
    "            A_P_pairs = random.sample(list(combinations(same_class_idx,2)),k=ap_pairs) #Generating Anchor-Positive pairs\n",
    "        else:\n",
    "            same_class_sampleer_idx = random.choice(range(len(same_class_idx)-15))\n",
    "            A_P_pairs = random.sample(list(combinations(same_class_idx[same_class_sampleer_idx:same_class_sampleer_idx+15],2)),k=ap_pairs) #Generating Anchor-Positive pairs\n",
    "        Neg_idx = random.sample(list(diff_class_idx),k=an_pairs)\n",
    "        \n",
    "\n",
    "        #train\n",
    "        A_P_len = len(A_P_pairs)\n",
    "        Neg_len = len(Neg_idx)\n",
    "        for ap in A_P_pairs[:int(A_P_len*trainsize)]:\n",
    "            Anchor = data_xy[0][ap[0]]\n",
    "            Positive = data_xy[0][ap[1]]\n",
    "            for n in Neg_idx:\n",
    "                Negative = data_xy[0][n]\n",
    "                triplet_train_pairs.append([Anchor,Positive,Negative])               \n",
    "        #test\n",
    "        for ap in A_P_pairs[int(A_P_len*trainsize):]:\n",
    "            Anchor = data_xy[0][ap[0]]\n",
    "            Positive = data_xy[0][ap[1]]\n",
    "            for n in Neg_idx:\n",
    "                Negative = data_xy[0][n]\n",
    "                triplet_test_pairs.append([Anchor,Positive,Negative])    \n",
    "                \n",
    "    return np.array(triplet_train_pairs), np.array(triplet_test_pairs)\n",
    "\n",
    "def triplet_generation(X, neg_class_num=2,testsize=0.3):\n",
    "    \"\"\"\n",
    "    Generating triplet pairs. \n",
    "\n",
    "    Args:\n",
    "        x: The input data should be in the shape of (num_classes, sample_per_class, features)\n",
    "        neg_class_num: How many negative classes to pair with the Anchor-Positive pair\n",
    "    Returns:\n",
    "        Triplet Pairs: A array containing (Anchor, Positive, Negative) pairs\n",
    "\n",
    "    \"\"\"    \n",
    "    trainsize = 1-testsize  \n",
    "    if len(X.shape) == 3:    \n",
    "        Train_Pair_input = []\n",
    "        Test_Pair_input = []\n",
    "        for label_idx in range(X.shape[0]):\n",
    "            for i in range(4):\n",
    "                anchor = X[label_idx][i]\n",
    "                if i == 3:\n",
    "                    positive = X[label_idx][i-2]\n",
    "                else:\n",
    "                    positive = X[label_idx][i+1]\n",
    "\n",
    "                #Step 2 get negative\n",
    "                negative_list = random.sample([i for i in range(0,X.shape[0]) if i not in [label_idx]],k=neg_class_num)\n",
    "                data_len = len(negative_list)\n",
    "                #Train portion\n",
    "                for neg_ind in negative_list[:int(trainsize*data_len)]:\n",
    "                    for neg_mem_ind in random.sample(range(3),k=3):\n",
    "                        negative = X[neg_ind][neg_mem_ind]\n",
    "\n",
    "                        Train_Pair_input.append([anchor,positive,negative])\n",
    "                #Test portion   \n",
    "                for neg_ind in negative_list[int(trainsize*data_len):]:\n",
    "                    for neg_mem_ind in random.sample(range(3),k=3):\n",
    "                        negative = X[neg_ind][neg_mem_ind]\n",
    "\n",
    "                        Test_Pair_input.append([anchor,positive,negative])                \n",
    "                        \n",
    "                    \n",
    "\n",
    "\n",
    "        return np.array(Train_Pair_input), np.array(Test_Pair_input)\n",
    "    \n",
    "    else:\n",
    "        print(\"Warning!!!! Please reshape X into (num_classes,sample_per_classes,features)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# X_train = triplet_generation(trn_bl_ivector_10Classes.reshape(100,3,600), neg_class_num=20)\n",
    "\n",
    "\n",
    "## Triplet NN\n",
    "\n",
    "\n",
    "def create_base_network(in_dims, out_dims):\n",
    "    \"\"\"\n",
    "    Base network to be shared.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(600, input_shape=(in_dims,),activation='relu'))\n",
    "    return model\n",
    "\n",
    "anchor_input = Input((600, ), name='anchor_input')\n",
    "positive_input = Input((600, ), name='positive_input')\n",
    "negative_input = Input((600, ), name='negative_input')\n",
    "\n",
    "# Shared embedding layer for positive and negative items\n",
    "Shared_DNN = create_base_network(600,600)\n",
    "\n",
    "\n",
    "encoded_anchor = Shared_DNN(anchor_input)\n",
    "encoded_positive = Shared_DNN(positive_input)\n",
    "encoded_negative = Shared_DNN(negative_input)\n",
    "\n",
    "merged_vector = concatenate([encoded_anchor, encoded_positive, encoded_negative], axis=-1)\n",
    "\n",
    "\n",
    "all_data = np.column_stack((trn_bl_ivector.reshape(classes,3,600),dev_bl_ivector.reshape(classes,1,600)))\n",
    "\n",
    "label_ls = []\n",
    "for i in range(3631):\n",
    "    for label in range(4):\n",
    "        label_ls.append(i)\n",
    "label_array = np.array(label_ls)\n",
    "\n",
    "\n",
    "\n",
    "confu_num2_ls = []\n",
    "confu_num3_ls = []\n",
    "\n",
    "confusion_err=444\n",
    "total_loss_history = []\n",
    "total_valloss_history = []\n",
    "\n",
    "print('all data dim = {}'.format(all_data.shape))\n",
    "\n",
    "\n",
    "\n",
    "# if i == 0:\n",
    "    # None\n",
    "# else:\n",
    "    # model.load_weights(foldername+filename+'.hdf5')\n",
    "# X_train, X_test = triplet_generation(all_data,neg_class_num=50)\n",
    "#Use trained model to predict\n",
    "trained_model = Model(inputs=anchor_input, outputs=encoded_anchor)\n",
    "trained_model.load_weights('./task2_trainall/triplet_Dense600_87nd_err285_C0.5.hdf5')\n",
    "# trained_model.load_weights(filename+'.hdf5')\n",
    "\n",
    "transformed_trn_bl_ivector = trained_model.predict(trn_bl_ivector)\n",
    "transformed_dev_ivector = trained_model.predict(dev_ivector)\n",
    "transformed_trn_ivector = trained_model.predict(trn_ivector)\n",
    "transformed_tst_ivector = trained_model.predict(tst_ivector)\n",
    "transformed_dev_bl_ivector = trained_model.predict(dev_bl_ivector)\n",
    "transformed_spk_mean, transformed_spk_mean_label = make_spkvec(transformed_trn_bl_ivector,trn_bl_id)\n",
    "\n",
    "\n",
    "\n",
    "##############################1st Report#####################################\n",
    "# Cosine distance scoring\n",
    "scores = transformed_spk_mean.dot(transformed_dev_ivector.transpose())\n",
    "\n",
    "# # Multi-target normalization\n",
    "# blscores = transformed_spk_mean.dot(trn_bl_ivector.transpose())\n",
    "# mnorm_mu = np.mean(blscores,axis=1)\n",
    "# mnorm_std = np.std(blscores,axis=1)\n",
    "# for iter in range(np.shape(scores)[1]):\n",
    "#     scores[:,iter]= (scores[:,iter] - mnorm_mu) / mnorm_std\n",
    "dev_scores = np.max(scores,axis=0)\n",
    "\n",
    "# Top-S detector EER\n",
    "dev_EER = calculate_EER(dev_trials, dev_scores)\n",
    "\n",
    "#divide trial label into target and non-target, plus confusion error(blacklist, fail at blacklist detector)\n",
    "dev_identified_label = spk_mean_label[np.argmax(scores,axis=0)]\n",
    "dev_trials_label = np.append( dev_bl_id,dev_bg_id)\n",
    "dev_trials_utt_label = np.append( dev_bl_utt,dev_bg_utt)\n",
    "\n",
    "# Top-1 detector EER\n",
    "dev_trials_confusion = get_trials_label_with_confusion(dev_identified_label, dev_trials_label, dev2train, dev_trials )\n",
    "dev_EER_confusion,confu_num1 = calculate_EER_with_confusion(dev_scores,dev_trials_confusion)\n",
    "\n",
    "\n",
    "################################2nd Report######################################\n",
    "print('\\nTest set score using train set:')\n",
    "#Cosine distance scoring on Test set\n",
    "scores = transformed_spk_mean.dot(transformed_tst_ivector.transpose())\n",
    "\n",
    "# Multi-target normalization\n",
    "# blscores = spk_mean.dot(trn_bl_ivector.transpose())\n",
    "# mnorm_mu = np.mean(blscores,axis=1)\n",
    "# mnorm_std = np.std(blscores,axis=1)\n",
    "# for iter in range(np.shape(scores)[1]):\n",
    "    # scores[:,iter]= (scores[:,iter] - mnorm_mu) / mnorm_std\n",
    "tst_scores = np.max(scores,axis=0)\n",
    "\n",
    "# top-S detector EER\n",
    "tst_EER = calculate_EER(tst_trials, tst_scores)\n",
    "\n",
    "#divide trial label into target and non-target, plus confusion error(blacklist, fail at blacklist detector)\n",
    "tst_identified_label = spk_mean_label[np.argmax(scores,axis=0)]\n",
    "\n",
    "# Top-1 detector EER\n",
    "tst_trials_confusion = get_trials_label_with_confusion(tst_identified_label, tst_trials_label, test2train, tst_trials )\n",
    "tst_EER_confusion,confu_num2 = calculate_EER_with_confusion(tst_scores,tst_trials_confusion)    \n",
    "X_train = None\n",
    "X_test = None\n",
    "Anchor = None\n",
    "Positive = None\n",
    "Negative = None\n",
    "Anchor_test = None\n",
    "Positive_test = None\n",
    "Negative_test = None\n",
    "\n",
    "################################3rd Report #########################################\n",
    "print('\\nTest set score using train + dev set:')\n",
    "# get dev set id consistent with Train set\n",
    "dev_bl_id_along_trnset = []\n",
    "for iter in range(len(dev_bl_id)):\n",
    "    dev_bl_id_along_trnset.extend([dev2train[dev_bl_id[iter]]])\n",
    "\n",
    "# Calculating speaker mean vector\n",
    "transformed3_spk_mean, spk_mean_label = make_spkvec(np.append(transformed_trn_bl_ivector,transformed_dev_bl_ivector,0),np.append(trn_bl_id,dev_bl_id_along_trnset))\n",
    "\n",
    "#Cosine distance scoring on Test set\n",
    "scores = transformed3_spk_mean.dot(transformed_tst_ivector.transpose())\n",
    "# tst_scores = np.max(scores,axis=0)\n",
    "\n",
    "\n",
    "# Multi-target normalization\n",
    "# blscores = transformed3_spk_mean.dot(np.append(transformed_trn_bl_ivector.transpose(),transformed_dev_bl_ivector.transpose(),axis=1))\n",
    "# mnorm_mu = np.mean(blscores,axis=1)\n",
    "# mnorm_std = np.std(blscores,axis=1)\n",
    "# for iter in range(np.shape(scores)[1]):\n",
    "    # scores[:,iter]= (scores[:,iter] - mnorm_mu) / mnorm_std\n",
    "tst_scores = np.max(scores,axis=0)\n",
    "\n",
    "# top-S detector EER\n",
    "tst_EER = calculate_EER(tst_trials, tst_scores)\n",
    "\n",
    "#divide trial label into target and non-target, plus confusion error(blacklist, fail at blacklist detector)\n",
    "tst_identified_label = spk_mean_label[np.argmax(scores,axis=0)]\n",
    "\n",
    "# Top-1 detector EER\n",
    "tst_trials_confusion = get_trials_label_with_confusion(tst_identified_label, tst_trials_label, test2train,tst_trials )\n",
    "tst_EER_confusion,confu_num3 = calculate_EER_with_confusion(tst_scores,tst_trials_confusion)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
