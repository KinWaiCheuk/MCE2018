{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "import matplotlib \n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from time import time\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restricting GPU memory\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "gpu = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpu[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataloader, TNN, evaluation # Loading helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev2train, test2train = dataloader.creating_id_mapping()\n",
    "\n",
    "# Getting i-vectors\n",
    "trn_bl_ivector, trn_bg_ivector, dev_bl_ivector, dev_bg_ivector, tst_ivector = dataloader.get_ivectors()\n",
    "\n",
    "# Loading labels for task 2\n",
    "trn_bl_id, trn_bg_id, dev_bl_id, dev_bg_id, tst_id = dataloader.get_spk_ids()\n",
    "dev_trials_label = np.append(dev_bl_id,dev_bg_id)\n",
    "\n",
    "# Making labels for task 1\n",
    "trn_ivector = np.append(trn_bl_ivector, trn_bg_ivector,axis=0) # combining bg and bl speakers into a single vector\n",
    "trn_trials = np.append( np.ones([len(trn_bl_ivector), 1]), np.zeros([len(trn_bg_ivector), 1]))\n",
    "dev_ivector = np.append(dev_bl_ivector, dev_bg_ivector,axis=0) # combining bg and bl\n",
    "dev_trials = np.append( np.ones([len(dev_bl_id), 1]), np.zeros([len(dev_bg_id), 1]))\n",
    "tst_trials, tst_trials_label = dataloader.get_tst_trials()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "anchor_input (InputLayer)       (None, 600)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "positive_input (InputLayer)     (None, 600)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "negative_input (InputLayer)     (None, 600)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 600)          360600      anchor_input[0][0]               \n",
      "                                                                 positive_input[0][0]             \n",
      "                                                                 negative_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1800)         0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "                                                                 sequential_1[3][0]               \n",
      "==================================================================================================\n",
      "Total params: 360,600\n",
      "Trainable params: 360,600\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model, anchor_input, encoded_anchor = TNN.create_TNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier1 = KNeighborsClassifier(n_neighbors=3, weights='uniform', algorithm='auto', \n",
    "                            leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=8)\n",
    "classifier2 = KNeighborsClassifier(n_neighbors=3, weights='uniform', algorithm='auto', \n",
    "                            leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting TNN embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = Model(inputs=anchor_input, outputs=encoded_anchor)\n",
    "trained_model.load_weights('./weights/triplet_Dense600_87nd_err286_C1.hdf5')\n",
    "transformed_trn_bl_ivector = trained_model.predict(trn_bl_ivector)\n",
    "transformed_dev_ivector = trained_model.predict(dev_ivector)\n",
    "transformed_trn_ivector = trained_model.predict(trn_ivector)\n",
    "transformed_tst_ivector = trained_model.predict(tst_ivector)\n",
    "transformed_dev_bl_ivector = trained_model.predict(dev_bl_ivector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating on testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on trainset only, test on testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top S detector EER is 8.36%\n",
      "time used = 1.39e+02\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "classifier1.fit(transformed_trn_ivector, trn_trials)\n",
    "task1_pred = classifier1.predict_proba(transformed_tst_ivector)\n",
    "err = dataloader.calculate_EER(tst_trials,task1_pred[:,1])\n",
    "print(f'time used = {time()-start:.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 detector EER is 14.08% (Total confusion error is 550)\n",
      "time used = 29.4\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "classifier2.fit(transformed_trn_bl_ivector, trn_bl_id)\n",
    "task2_pred = classifier2.predict(transformed_tst_ivector)\n",
    "tst_trials_confusion = dataloader.get_trials_label_with_confusion(task2_pred, tst_trials_label, test2train, tst_trials )\n",
    "dev_EER_confusion = dataloader.calculate_EER_with_confusion(task1_pred[:,1],tst_trials_confusion)\n",
    "print(f'time used = {time()-start:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on trainset and devset, test on testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top S detector EER is 8.26%\n",
      "time used = 1.56e+02\n"
     ]
    }
   ],
   "source": [
    "# getting dev ids to train id conversion\n",
    "dev_bl_id_along_trnset = []\n",
    "for iter in range(len(dev_bl_id)):\n",
    "    dev_bl_id_along_trnset.extend([dev2train[dev_bl_id[iter]]])\n",
    "\n",
    "combined_embedding = np.append(transformed_trn_ivector,transformed_dev_ivector,0)\n",
    "combined_trials = np.append(trn_trials,dev_trials)    \n",
    "    \n",
    "combined_bl_embedding = np.append(transformed_trn_bl_ivector,transformed_dev_bl_ivector,0)\n",
    "combined_ids = np.append(trn_bl_id,dev_bl_id_along_trnset)\n",
    "\n",
    "# predictions = cosine_similarity(transformed_tst_ivector, combined_embedding, combined_labels)\n",
    "# err = dataloader.calculate_EER(tst_trials,predictions)\n",
    "\n",
    "start = time()\n",
    "classifier1.fit(combined_embedding, combined_trials)\n",
    "task1_pred = classifier1.predict_proba(transformed_tst_ivector)\n",
    "err = dataloader.calculate_EER(tst_trials,task1_pred[:,1])\n",
    "print(f'time used = {time()-start:.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 detector EER is 13.48% (Total confusion error is 402)\n",
      "time used = 43.3\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "classifier2.fit(combined_bl_embedding, combined_ids)\n",
    "task2_pred = classifier2.predict(transformed_tst_ivector)\n",
    "tst_trials_confusion = dataloader.get_trials_label_with_confusion(task2_pred, tst_trials_label, test2train, tst_trials )\n",
    "dev_EER_confusion = dataloader.calculate_EER_with_confusion(task1_pred[:,1],tst_trials_confusion)\n",
    "print(f'time used = {time()-start:.3}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
